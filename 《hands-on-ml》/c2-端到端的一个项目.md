# 如何走完一套机器学习项目

## 获取数据

要使真实数据

## 观察大局

### 性能指标的选择

#### 回归问题

可以用rmse、mae等。范数指标越高，越关注大值；离群值呈现正态分布时用rmse非常好

- rmse

  - ```python
    from sklearn.metrics import mean_squared_error
    
    housing_predictions = lin_reg.predict(housing_prepared)
    lin_mse = mean_squared_error(housing_labels, housing_predictions)
    lin_rmse = np.sqrt(lin_mse)
    ```

- mae

  - ```python
    from sklearn.metrics import mean_absolute_error
    
    lin_mae = mean_absolute_error(housing_labels, housing_predictions)
    ```

    

#### 分类问题



## 数据清洗

快速查看直方图：

```python
data.hist(bins=50)
```

#### 创建测试集

使用随机数生成的方式：

使用哈希函数生成的方式：

使用sklearn进行纯随机抽样:

```python
from sklearn.model_selection import train_test_split
train_set, test_set = train_set_split(data, test_size=0.2, random_state=42)
```

使用sklearn进行分层抽样：

```python
# 1. 先根据某个字段整理出频数
# 2. 调包
from sklearn.model_selection import StratifiedShuffleSplit
split = StratifiedShuffleSplit(n_splits, test_size=0.2, random_state=42)  # 一般只采用一次分割，因此下面也就循环1轮
for train_ind, test_ind in split.split(data, data['频数字段'])
	train_set = data.loc[train_ind]
    test_set = data.loc[test_ind]
# 3. 把中间字段（频数）drop掉
```

#### 统计性探索

- 相关系数

```python
corr_mat = data.corr()  # 相关系数
```

- 可以使用pairplot绘制正交实验图

- 创建一些新的属性

#### 三大值处理

- 缺失值

​	直接使用专用包：
```python
from sklearn.impute import SimpleImputer
​	imputer = SimpleImputer(strategy='median')
​	imputer.fit_transform(data)
```

- 异常值
- 重复值

#### 文本处理
- 常规编码
	```python
	# 编码从0开始
	from sklearn.preprocessing import OrdinalEncoder
	ordinal_encoder = OrdinalEncoder()
	data[''] = ordinal_encoder.fit_transform(data[''])
	
	ordinal_encoder.categories_  # 访问编码对应的文本列表
	```
- 独热编码

```python
from sklearn.proprecessing import OneHotEncoder
cd = OneHotEncoder()
data_mat = cd.fit_transform(data[''])  # data_mat是一个scipy的稀疏矩阵结构

data_mat.to_array()  # 转换为array类型方便打印
cd.categories_  # 作用同
```

#### sk:自定义转换器

要以BaseEsitimator和TransformerMixin为基类 p71

```python
class MyTrans(BaseEsitimator, TransformerMixin):
    ### 一定要定义fit和transform
    ### fit_transform由TransformerMixin提供
    ### BaseEsitimator提供get_params和set_params
```

#### sk:转换流水线

- 使用PipeLine，对整张表进行处理

  - ```python
    # 转换流水线：一次性完成填充缺失值、增加属性、标准化
    from sklearn.pipeline import Pipeline
    from sklearn.preprocessing import StandardScaler
    num_pipeline = Pipeline([
        ('imputer', SimpleImputer(strategy='median')),
        ('attribs_adder', CombinedAttributesAdder()),
        ('std_scaler', StandardScaler())
    ])
    data_num_tr = num_pipeline.fit_transform(data_num)
    ```



- 使用ColumnTransformer，根据不同列设置不同的处理方式

  - ```python
    from sklearn.compose import ColumnTransformer
    num_attribs = list(data_num)
    cat_attribs = ['ocean_proximity']
    full_pipeline = ColumnTransformer([
        ('num', num_pipeline, num_attribs),
        ('cat', OneHotEncoder(), cat_attribs)
    ])
    data_prepared = full_pipeline.fit_transform(data)
    ```

## 选择和训练模型

### 模型选择与参数选择

略。前面和后面已经提到

### 交叉验证

非常有效的检测模型的真实能力

```python
from sklearn.model_selection import cross_val_score

scores = cross_val_score(tree_reg, housing_prepared, housing_labels,  # 拟合问题就没有label
                         scoring="neg_mean_squared_error", cv=10)  # 得到的分数是-mse
tree_rmse_scores = np.sqrt(-scores)

# scoring='r2score'  # 评估的是拟合优度
```

### 参数调整

网格搜索非常强大

```python
from sklearn.model_selection import GridSearchCV

param_grid = [
    # try 12 (3×4) combinations of hyperparameters
    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},
    # then try 6 (2×3) combinations with bootstrap set as False
    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},
  ]

forest_reg = RandomForestRegressor(random_state=42)
# train across 5 folds, that's a total of (12+6)*5=90 rounds of training 
grid_search = GridSearchCV(forest_reg, param_grid, cv=5,
                           scoring='neg_mean_squared_error',
                           return_train_score=True)
grid_search.fit(housing_prepared, housing_labels)

# 获取最佳参数
grid_search.best_params_
# 获取整个最佳模型
grid_search.best_estimator_
# 获取对应参数和评估分数
cvres = grid_search.cv_results_
for mean_score, params in zip(cvres["mean_test_score"], cvres["params"]):
    print(np.sqrt(-mean_score), params)
输出：
63669.11631261028 {'max_features': 2, 'n_estimators': 3}
55627.099719926795 {'max_features': 2, 'n_estimators': 10}
53384.57275149205 {'max_features': 2, 'n_estimators': 30}
......
```